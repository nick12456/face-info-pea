<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Face Recognizer with Emotions</title>
<style>
  body{margin:0;background:#0b0b0c;color:#fff;font-family:sans-serif;text-align:center}
  video,canvas{width:100%;max-width:480px;border-radius:8px;margin-top:10px}
  #controls{margin:10px}
  input,button{padding:8px 12px;margin:4px;border-radius:6px;border:1px solid #444}
  #status{margin-top:10px;white-space:pre-line}
</style>
</head>
<body>
  <h2>Face Recognition Demo</h2>
  <div id="controls">
    <input id="nameInput" placeholder="Enter name" />
    <button onclick="enroll()">Enroll</button>
    <button onclick="verify()">Verify</button>
  </div>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>
  <div id="status">Loading modelsâ€¦</div>

<script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
<script>
const MODEL_URL="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/";
const video=document.getElementById("video");
const canvas=document.getElementById("canvas");
const ctx=canvas.getContext("2d");
const statusBox=document.getElementById("status");
let known=JSON.parse(localStorage.getItem("faces-db")||"{}");
const MATCH_THRESHOLD=0.58;

const motivationalLines = [
  "Keep pushing forward ðŸš€",
  "Your smile lights up the day âœ¨",
  "Stay strong, youâ€™re doing great ðŸ’ª",
  "Every moment is a new chance ðŸŒŸ",
  "Youâ€™ve got this ðŸ”¥",
  "Confidence suits you well ðŸ˜Ž",
  "Stay positive and unstoppable ðŸŒˆ"
];

function randomMotivation(){
  return motivationalLines[Math.floor(Math.random()*motivationalLines.length)];
}

async function startCamera(){
  const stream=await navigator.mediaDevices.getUserMedia({video:{facingMode:"user"}});
  video.srcObject=stream; await video.play();
  canvas.width=video.videoWidth; canvas.height=video.videoHeight;
}

async function loadModels(){
  await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
  await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
  await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
  await faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL);
  await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
  statusBox.innerText="âœ… Models loaded";
}

function dist(a,b){let s=0;for(let i=0;i<a.length;i++){let d=a[i]-b[i];s+=d*d;}return Math.sqrt(s);}

async function captureDescriptor(){
  const opts=new faceapi.TinyFaceDetectorOptions({inputSize:160});
  const det=await faceapi.detectSingleFace(video,opts).withFaceLandmarks().withFaceDescriptor().withAgeAndGender().withFaceExpressions();
  if(!det){statusBox.innerText="No face detected";return null;}
  drawOverlay(det);
  return {descriptor:det.descriptor, age:Math.round(det.age), gender:det.gender, expr:det.expressions};
}

function drawOverlay(det){
  ctx.drawImage(video,0,0,canvas.width,canvas.height);
  const {x,y,width,height}=det.detection.box;
  ctx.strokeStyle="cyan"; ctx.lineWidth=2; ctx.strokeRect(x,y,width,height);

  // Show ALL expressions with % values
  ctx.font="12px sans-serif"; ctx.fillStyle="black"; ctx.fillRect(x,y-90,160,80);
  ctx.fillStyle="white"; let offset=0;
  for(const [emo,val] of Object.entries(det.expressions)){
    ctx.fillText(`${emo}: ${(val*100).toFixed(1)}%`,x+4,y-75+offset); offset+=12;
  }
}

async function enroll(){
  const name=document.getElementById("nameInput").value.trim();
  if(!name){alert("Enter name");return;}
  const res=await captureDescriptor(); if(!res) return;
  if(!known[name]) known[name]=[];
  known[name].push(Array.from(res.descriptor));
  localStorage.setItem("faces-db",JSON.stringify(known));
  statusBox.innerText=`Enrolled ${name} (${known[name].length} samples)\nAge:${res.age}, Gender:${res.gender}\nMotivation: ${randomMotivation()}`;
}

async function verify(){
  const name=document.getElementById("nameInput").value.trim();
  if(!name||!known[name]){alert("Name not enrolled");return;}
  const res=await captureDescriptor(); if(!res) return;
  const dists=known[name].map(v=>dist(res.descriptor,Float32Array.from(v)));
  const min=Math.min(...dists);
  if(min<MATCH_THRESHOLD){
    statusBox.innerText=`âœ… Verified as ${name}\nAge:${res.age}, Gender:${res.gender}\nTop emotion: ${topEmotion(res.expr)}\nMotivation: ${randomMotivation()}`;
  }else{
    statusBox.innerText=`âŒ Face does not match ${name}`;
  }
}

function topEmotion(exprs){
  let best="";let v=0;
  for(const k in exprs){if(exprs[k]>v){best=k;v=exprs[k];}}
  return best;
}

(async()=>{await startCamera();await loadModels();})();
</script>
</body>
</html>
